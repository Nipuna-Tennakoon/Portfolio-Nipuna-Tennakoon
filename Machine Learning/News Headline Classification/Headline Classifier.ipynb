{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('newsCorpora.csv', sep ='\\t', names = ['ID','Title','URL', 'Publisher', 'Category', 'Story', 'Hostname','Timestamp'])\n",
    "df=df[['Title','Category']]\n",
    "dict = {'b':'Business', 't':'Science', 'e':'Entertainment', 'm':'Health'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_category(x):\n",
    "    return dict[x]\n",
    "df['Category'] = df['Category'].apply(lambda x: update_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422414</th>\n",
       "      <td>Surgeons to remove 4-year-old's rib to rebuild...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422415</th>\n",
       "      <td>Boy to have surgery on esophagus after battery...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422416</th>\n",
       "      <td>Child who swallowed battery to have reconstruc...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422417</th>\n",
       "      <td>Phoenix boy undergoes surgery to repair throat...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422418</th>\n",
       "      <td>Phoenix boy undergoes surgery to repair throat...</td>\n",
       "      <td>Health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>422419 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Title  Category\n",
       "0       Fed official says weak data caused by weather,...  Business\n",
       "1       Fed's Charles Plosser sees high bar for change...  Business\n",
       "2       US open: Stocks fall after Fed official hints ...  Business\n",
       "3       Fed risks falling 'behind the curve', Charles ...  Business\n",
       "4       Fed's Plosser: Nasty Weather Has Curbed Job Gr...  Business\n",
       "...                                                   ...       ...\n",
       "422414  Surgeons to remove 4-year-old's rib to rebuild...    Health\n",
       "422415  Boy to have surgery on esophagus after battery...    Health\n",
       "422416  Child who swallowed battery to have reconstruc...    Health\n",
       "422417  Phoenix boy undergoes surgery to repair throat...    Health\n",
       "422418  Phoenix boy undergoes surgery to repair throat...    Health\n",
       "\n",
       "[422419 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=0.10,random_state=1)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_dict = {}\n",
    "\n",
    "def encode_category(x):\n",
    "    if x not in encode_dict.keys():\n",
    "        encode_dict[x]=len(encode_dict)\n",
    "    return encode_dict[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Encode Category'] = df['Category'].apply(lambda x:encode_category(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15275\n",
       "0    11438\n",
       "2    10963\n",
       "3     4566\n",
       "Name: Encode Category, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Encode Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Business': 0, 'Entertainment': 1, 'Science': 2, 'Health': 3}\n"
     ]
    }
   ],
   "source": [
    "print(encode_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(df['Title'],df['Encode Category'],stratify=df['Encode Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11456\n",
       "0     8578\n",
       "2     8222\n",
       "3     3425\n",
       "Name: Encode Category, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3819\n",
       "0    2860\n",
       "2    2741\n",
       "3    1141\n",
       "Name: Encode Category, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York second in nation for chikungunya'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New York second in nation for chikungunya 20\n"
     ]
    }
   ],
   "source": [
    "cnt_=[]\n",
    "for i in X_train:\n",
    "    cnt_.append(len(i.split()))\n",
    "print(X_train[max(cnt_)],max(cnt_))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define tokenizer (limiting vocab size if needed)\n",
    "MAX_VOCAB_SIZE = 20000  # Adjust based on dataset size\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit tokenizer on the text data\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine max sequence length\n",
    "MAX_SEQ_LENGTH = max(len(seq) for seq in X_train_seq)  # or set a fixed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to ensure uniform input size\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode labels\n",
    "Y_train_cat = to_categorical(Y_train, num_classes=4)\n",
    "Y_test_cat = to_categorical(Y_test, num_classes=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 896, 1978,  381, ...,    0,    0,    0],\n",
       "       [  47,  635,  837, ...,    0,    0,    0],\n",
       "       [  72,   13,  606, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 648, 3226,  964, ...,    0,    0,    0],\n",
       "       [  32,   41,  549, ...,    0,    0,    0],\n",
       "       [ 164,  854, 1100, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "embedding_dim = 100  # Adjust based on complexity\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=MAX_VOCAB_SIZE, output_dim=embedding_dim, input_length=MAX_SEQ_LENGTH),\n",
    "    LSTM(64),\n",
    "    Dense(4, activation='softmax')  # 4 output classes\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',  # Entropy-based loss function\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "991/991 [==============================] - 68s 65ms/step - loss: 0.5197 - accuracy: 0.7884 - val_loss: 0.2779 - val_accuracy: 0.9061\n",
      "Epoch 2/10\n",
      "991/991 [==============================] - 70s 71ms/step - loss: 0.1778 - accuracy: 0.9418 - val_loss: 0.2859 - val_accuracy: 0.9038\n",
      "Epoch 3/10\n",
      "991/991 [==============================] - 62s 62ms/step - loss: 0.1048 - accuracy: 0.9662 - val_loss: 0.2973 - val_accuracy: 0.9038\n",
      "Epoch 4/10\n",
      "991/991 [==============================] - 67s 68ms/step - loss: 0.0761 - accuracy: 0.9763 - val_loss: 0.3494 - val_accuracy: 0.9046\n",
      "Epoch 5/10\n",
      "991/991 [==============================] - 73s 74ms/step - loss: 0.0582 - accuracy: 0.9812 - val_loss: 0.3516 - val_accuracy: 0.8968\n",
      "Epoch 6/10\n",
      "991/991 [==============================] - 69s 69ms/step - loss: 0.0458 - accuracy: 0.9845 - val_loss: 0.4371 - val_accuracy: 0.9009\n",
      "Epoch 7/10\n",
      "991/991 [==============================] - 68s 69ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.3873 - val_accuracy: 0.8978\n",
      "Epoch 8/10\n",
      "991/991 [==============================] - 71s 72ms/step - loss: 0.0302 - accuracy: 0.9905 - val_loss: 0.4288 - val_accuracy: 0.8973\n",
      "Epoch 9/10\n",
      "991/991 [==============================] - 72s 73ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.4814 - val_accuracy: 0.8950\n",
      "Epoch 10/10\n",
      "991/991 [==============================] - 69s 70ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.5491 - val_accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_pad, Y_train_cat,  # Tokenized and padded input & one-hot labels\n",
    "    validation_data=(X_test_pad, Y_test_cat),  # Validation set\n",
    "    epochs=10,  # Number of iterations (adjustable)\n",
    "    batch_size=32,  # Number of samples per batch\n",
    "    verbose=1  # Display training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - 4s 11ms/step - loss: 0.5491 - accuracy: 0.8942\n",
      "Test Accuracy: 0.8942\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test_pad, Y_test_cat)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Function to preprocess and predict\n",
    "def predict_class(sentence, tokenizer, model, max_length):\n",
    "    # Tokenize the input sentence\n",
    "    sequence = tokenizer.texts_to_sequences([sentence])\n",
    "    \n",
    "    # Pad the sequence to match training input length\n",
    "    padded_sequence = pad_sequences(sequence, maxlen=max_length, padding='post', truncating='post')\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    \n",
    "    # Get class with highest probability\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    \n",
    "    return predicted_class, sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, [[699, 1101, 36, 1]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = input(\"Type your sentence within word count 19\")\n",
    "predict_class(sentence,tokenizer,model,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Business', 'Entertainment', 'Science', 'Health'])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_dict = {'Business': 0, 'Entertainment': 1, 'Science': 2, 'Health': 3}\n",
    "output = encode_dict['Business']\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
